# DyGenePT Configuration â€” Replogle K562 Essential
# For fair comparison with LangPert (ICLR 2025 MLGenX)
#
# Usage:
#   python -m src.train --config configs/replogle_k562.yaml
#   python -m src.train_cv --config configs/replogle_k562.yaml  # 5-fold CV

# ========================
# Paths
# ========================
paths:
  gene_info: "data/Homo_sapiens_gene_info_with_go_and_pathways.tsv"
  facet_output: "data/replogle_k562/gene_facets.jsonl"
  facet_embeddings: "data/replogle_k562/gene_facet_embeddings.pt"
  perturb_data_dir: "data/perturb_data"
  scgpt_checkpoint: "checkpoints/scgpt/whole_human"
  output_dir: "outputs/replogle_k562"
  kg_dir: "data/kg"

# ========================
# LLM API (Module 1 - Facet Decomposition)
# ========================
llm:
  base_url: "https://yunwu.ai/v1"
  api_key: "${oc.env:LLM_API_KEY,\"\"}"
  model: "gemini-3-pro-preview"
  temperature: 0.3
  max_tokens: 8192
  batch_size: 128
  retry_max: 3
  retry_delay: 2

# ========================
# Facets Definition
# ========================
facets:
  num_facets: 4
  names:
    - "Molecular Function & Protein Interactions"
    - "Biological Pathways & Signaling"
    - "Gene Regulation & Transcriptional Control"
    - "Loss-of-Function Impact & Cellular Fitness"

# ========================
# Embedding Model (Module 1 - Text Encoding)
# ========================
embedding:
  backend: "local"
  # --- local backend ---
  model_name: "FremyCompany/BioLORD-2023-M"
  pooling: "mean"
  max_length: 256
  # --- api backend (used when backend=api) ---
  api:
    base_url: "https://api.siliconflow.cn/v1"
    api_key: "${oc.env:EMBED_API_KEY,\"\"}"
    model: "Qwen/Qwen3-Embedding-8B"
    dimensions: 768
    batch_limit: 32
    concurrency: 8
    retry_max: 3
    retry_delay: 2
  # --- common ---
  batch_size: 64
  embed_dim: 768

# ========================
# Cell Encoder (Module 2 - scGPT)
# ========================
cell_encoder:
  model_name: "scGPT"
  embed_dim: 512
  freeze_layers: -2
  max_seq_len: 3000

# ========================
# Cross-Attention (Module 3)
# ========================
cross_attention:
  num_heads: 8
  hidden_dim: 768
  dropout: 0.1

# ========================
# Perturbation Type Encoding
# ========================
perturbation_type:
  enabled: true
  num_types: 3
  type_names:
    - "activation"
    - "repression"
    - "knockout"

# ========================
# Perturbation Decoder (Module 4)
# ========================
decoder:
  hidden_dims: [512, 256]
  dropout: 0.1
  gene_embed_aware: true
  gene_embed_dim: 512
  gene_embed_lr_scale: 0.1
  use_gene_graph: false
  num_go_layers: 2

# ========================
# Training
# ========================
training:
  dataset: "replogle_k562_essential"
  seed: 42
  epochs: 15
  batch_size: 128
  lr: 1.0e-4
  weight_decay: 1.0e-5
  scheduler: "cosine"
  warmup_steps: 500
  gradient_clip: 1.0
  eval_every: 1
  save_best: true
  early_stopping_patience: 3
  loss:
    mse_weight: 1.0
    de_mse_weight: 0.5
    direction_weight: 0.1
  cross_validation:
    enabled: true
    n_folds: 5
    split_mode: "simulation"

# ========================
# Dataset-specific settings
# ========================
dataset_configs:
  replogle_k562_essential:
    data_name: "replogle_k562_essential"
    split_mode: "simulation"
    single_gene_only: true
    pert_type: 1                     # CRISPRi = repression

# ========================
# Evaluation
# ========================
evaluation:
  top_de_genes: 20
  metrics:
    - "mse"
    - "mae"
    - "pearson_top20"
    - "pearson_delta_top20"
    - "direction_accuracy"

# ========================
# KG Text Enrichment (Step 1.5)
# ========================
kg_enrichment:
  enabled: true
  string_evidence_filter:
    - "experiments"
    - "database"
  max_neighbors: 5

# ========================
# KG Facet Imputation (Step 4)
# ========================
imputation:
  enabled: true
  max_neighbors: 20
  min_informed_neighbors: 2
  confidence_cap: 0.8
  num_rounds: 3
  evidence_weights:
    experiments: 1.0
    database: 0.8
    experiments_transferred: 0.5
    textmining: 0.3
    textmining_transferred: 0.2
